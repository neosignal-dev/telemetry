Cursor Rules for Telemetry DevOps Project

Project Overview

This project simulates a satellite internet telemetry system with the following components:
	•	Generator: produces synthetic satellite telemetry data (latency, bandwidth, battery, packet loss, etc.).
	•	Collector: exposes API endpoints for external ingestion of telemetry events and pushes them to RabbitMQ.
	•	Processor: consumes telemetry from RabbitMQ, stores it into PostgreSQL, and exposes Prometheus metrics.
	•	Monitoring stack: Prometheus + Grafana with pre-provisioned dashboards.
	•	CI/CD: GitOps structure with Kubernetes manifests, Helm, and FluxCD.
	•	Infrastructure: Terraform + Ansible for Yandex Cloud (Kubernetes cluster + srv node for observability).

The system is designed for DevOps diploma purposes, showcasing IaC, CI/CD, observability, and GitOps best practices.

⸻

Coding Standards
	1.	Language: Python 3.11+ for microservices.
	2.	Style: PEP8 + type hints.
	3.	Services: All services must have Dockerfile and requirements.txt.
	4.	Metrics: Each service must expose Prometheus metrics under /metrics.
	5.	Logs: Use structured JSON logging (logging module, no prints).
	6.	Configuration: All configs via environment variables. Never hardcode secrets.

⸻

Repository Structure

├── docker-compose.dev.yml         # Local dev stack
├── gitops/                        # FluxCD GitOps configs
│   ├── apps/
│   ├── helm-repos/
│   └── infrastructure/
├── k8s/                           # Base k8s manifests with overlays
│   ├── base/
│   ├── namespaces/
│   └── overlays/prod/
├── monitoring/                    # Prometheus + Grafana configs
│   ├── grafana/
│   │   └── provisioning/
│   │       ├── dashboards/
│   │       └── datasources/
│   └── prometheus/
├── services/                      # Microservices
│   ├── telemetry-collector/
│   ├── telemetry-generator/
│   └── telemetry-processor/
├── srv/                           # Observability stack for srv node
└── README.md


⸻

Rules for Cursor AI
	1.	Do not modify repository structure unless explicitly asked.
	2.	Do not commit secrets. Use placeholders and Kubernetes Secret objects.
	3.	When writing Kubernetes manifests, prefer Kustomize patches and overlays.
	4.	Helm: Use Bitnami charts where possible. Custom charts only if necessary.
	5.	GitOps: All k8s configs go under gitops/. FluxCD syncs from this repo.
	6.	Terraform: Only manage Yandex Cloud infra in gitops/infrastructure/.
	7.	Ansible: Only manage provisioning of srv node (Docker, VMagent, Grafana, etc.).
	8.	Dockerfiles:
	•	Multi-stage builds.
	•	Non-root user.
	•	Pin versions (Python, dependencies).
	9.	CI/CD Pipelines:
	•	Use GitLab CI.
	•	Include jobs for linting, building images, running tests, and pushing manifests.
	10.	Observability:

	•	All microservices must expose Prometheus metrics.
	•	Grafana dashboards must be stored as JSON under monitoring/grafana/provisioning/dashboards/.
	•	Dashboards must be provisioned automatically at startup.

⸻

Naming Conventions
	•	Kubernetes namespaces: telemetry
	•	Docker images: telemetry-<service>
	•	Queues: telemetry.raw
	•	Metrics prefix: telemetry_
	•	Terraform resources: telemetry_<resource>

⸻

Example Tasks for Cursor
	1.	Add a new metric to telemetry-processor: Always update Prometheus exposition and extend Grafana dashboard.
	2.	Change RabbitMQ queue name: Update in generator, collector, processor, docker-compose, and k8s manifests.
	3.	Add alerting rule: Modify srv/vmalert/rules.yml and ensure Prometheus scrapes the right endpoint.
	4.	Update Terraform module: Keep all Yandex Cloud infra code in gitops/infrastructure/.

⸻

Forbidden Actions
	•	Do not delete monitoring stack.
	•	Do not push .env files or raw secrets.
	•	Do not break backward compatibility in service APIs unless explicitly asked.

⸻

Goal

This repository should:
	•	Run locally with docker compose -f docker-compose.dev.yml up.
	•	Deploy in Kubernetes via GitOps (FluxCD).
	•	Have monitoring and dashboards available out-of-the-box.
	•	Be clean, reproducible, and extensible.
